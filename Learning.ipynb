{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef9a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.document import DoclingDocument\n",
    "from docling.document_converter import PdfFormatOption , DocumentConverter\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346e2a8",
   "metadata": {},
   "source": [
    "# Convert a document\n",
    "The first thing that we want to do  is to take our original document , here it is a pdf document and convert it to **DoclingDocument** . A  **document converter** decompose the document into different Items as :  \n",
    "- Image items \n",
    "- Table items\n",
    "- Text items  \n",
    "\n",
    "And then we have different layout where every elements has different attributes. For example a text item will have a **text attribute** that will contains the text of the TextItem.  \n",
    "\n",
    "Here is a function that create a personnalized pipeline to convert a **pdf document** to a **DoclingDocument** .  \n",
    "In our pipeline I decided to use OCR and also generate picture images and extracts the table structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0753cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_with_pipeline (path:str) -> DoclingDocument:\n",
    "    \n",
    "    pipeline_options = PdfPipelineOptions(\n",
    "        do_ocr= True,\n",
    "        do_table_structure= True,\n",
    "        generate_picture_images= True\n",
    "    )\n",
    "    \n",
    "    converter = DocumentConverter(\n",
    "        format_options= {\n",
    "            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return converter.convert(path).document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a70af",
   "metadata": {},
   "source": [
    "Let's test it with the official `docling papper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docling_doc = convert_with_pipeline(\"../Docling/docs/docling.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cabb092",
   "metadata": {},
   "source": [
    "Let's see what kind of attributes has our **DoclingDocument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "DoclingDoc_attributes = list(docling_doc.__dict__.keys())\n",
    "DoclingDoc_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e6e424",
   "metadata": {},
   "source": [
    "You can see the different attributes that I told you before . \n",
    "\n",
    "Let's explore what every attributes contains.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3beac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name contains tha name of your file\n",
    "print(f\"The name of the doc is {docling_doc.name}\")\n",
    "\n",
    "# If you want to have the entire filename you can take it from the origin attributes\n",
    "print(f\"The entire filename is : {docling_doc.origin.filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6bb764",
   "metadata": {},
   "source": [
    "Ok now we have some infos about the the origin and the name of every doc , it can be useful for the retrievement , if we want to display the source  !\n",
    "\n",
    "Let's see what contains the body and the groups of this document :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e062a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The body attributes\n",
    "body = docling_doc.body\n",
    "body_attributes = list(body.__dict__.keys())\n",
    "print(f\"The attributes of a the body are : \\n{body_attributes}\\n\")\n",
    "\n",
    "\n",
    "#Let's see the children\n",
    "print(f\"The children of the body are \\n{body.children}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0762d5",
   "metadata": {},
   "source": [
    "<u>Quick explanation :</u>  \n",
    "\n",
    "As I told you the document is decomposed into differents items , the body here contains these items in the order of the document.  \n",
    "\n",
    "**PS**: A group is a list of bullet point \n",
    "\n",
    "Let's move to another attribute , the **groups** one (smooth transition init? )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae06ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does groups contains\n",
    "group_attribute = docling_doc.groups\n",
    "print(f\" Groups contains a list of ListGroup here are they: \\n {group_attribute}\\n\")\n",
    "\n",
    "#Let's see what a ListGroup contains\n",
    "list_group0 = group_attribute[0]\n",
    "print(f\"Here are the attributes of a ListGroup item: \\n{list(list_group0.__dict__.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fee861",
   "metadata": {},
   "source": [
    "What really matters in  a group is :  \n",
    "\n",
    "- The children:  \n",
    "It contains the different items of the list and number of their items \n",
    "- The label :\n",
    "It contains the label of the group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11019183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The children of the group \n",
    "print(f\"The children of this group are :\\n {list_group0.children}\\n\")\n",
    "\n",
    "# You can see the different text part that contains the group \n",
    "\n",
    "print(f\"The group label is {list_group0.label} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886b6b3b",
   "metadata": {},
   "source": [
    "Okay you may think that is not the most improtant thing for chunking and you're right !\n",
    "So for that we can see the **text** attributes that contains all the TextItems of your document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd52ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text elements\n",
    "text_items = docling_doc.texts\n",
    "\n",
    "print(f\"There are {len(text_items)} text items in the document\\n\")\n",
    "\n",
    "#Let's see the attributes of a TextItem \n",
    "print(f\"A TextItem has these attributes:\\n {list(text_items[0].__dict__)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83de68",
   "metadata": {},
   "source": [
    "What in my opinion can be useful are thes attributes :  \n",
    "\n",
    "- The **label** that shows you if the Item is a *section_header* , a *page_header* or *text*  \n",
    "- The **prov** which is a list of **ProvenanceItem** where you can find the *page_no* of the TextItem but also a feature that I think is amazing: **a bounding box coordinates** , it allows to afterall highlight the following TextItem !  \n",
    "- The **text** of the TextItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4216829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The text \n",
    "print(f\" Here is the text of the first Item :\\n{text_items[0].text}\")\n",
    "\n",
    "#The provenance of the text\n",
    "print(f\"The prov object is :\\n {text_items[0].prov}\")\n",
    "\n",
    "#Let's the page of the TextItem\n",
    "print(f\"The page number is :\\n{text_items[0].prov[0].page_no}\\nand the box that contains the text item is :\\n{text_items[0].prov[0].bbox}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedfd7f9",
   "metadata": {},
   "source": [
    "That's nice but the thing is that I discovered this framework while I was looking for a way to include **tables** and **images** in my package: QuickRAG.  \n",
    "\n",
    "**So what about the images ?**  \n",
    "\n",
    "No worries the document contains an attribute: **pictures** that is a list of **PictureItem** where each picture has different attributes and a usual here are the most important ones:  \n",
    "\n",
    "- The **Label**\n",
    "- The **provenance**\n",
    "- The **image** attributes that contains the base64 code of the picture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image\n",
    "image_list = docling_doc.pictures\n",
    "print(f'Here is the list of images that the Document contains :\\n{image_list}\\n')\n",
    "print(f\"It contains {len(image_list)} images\")\n",
    "\n",
    "#Attributes of one image\n",
    "picture_attributes = print(f\"The attributes of an image are :\\n{list(image_list[0].__dict__)}\\n\")\n",
    "\n",
    "#Label of the image\n",
    "label = image_list[0].label\n",
    "print(f\"Here is the label of a picture:\\n{label}\\n\")\n",
    "\n",
    "#Image attributes\n",
    "image= image_list[0].image\n",
    "print(f\"The attributes of the image attributes are :\\n{list(image.__dict__.keys())}\")\n",
    "\n",
    "base_64_url = image_list[0].image.uri._url\n",
    "base64_image = str(base_64_url).split(\",\",1)[1]\n",
    "print(base64_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd4bf40",
   "metadata": {},
   "source": [
    "And finally the tables !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc3c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.chunking import HybridChunker,HierarchicalChunker\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499961f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "# chunker = HybridChunker(\n",
    "#     tokenizer=tok,\n",
    "    \n",
    "# )\n",
    "\n",
    "chunker = HierarchicalChunker()\n",
    "context_chunks = []\n",
    "chunks_list = list(chunker.chunk(dl_doc=docling_doc))\n",
    "\n",
    "for c in chunks_list:\n",
    "    cc = chunker.contextualize(c)\n",
    "    context_chunks.append(cc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64604a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_chunks[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3fd3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = chunks_list[2].meta.doc_items[0].prov[0].page_no\n",
    "bbox = chunks_list[2].meta.doc_items[0].prov[0].bbox\n",
    "chunks_list[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12742968",
   "metadata": {},
   "source": [
    "I defined a function that hightlights a specific part of the document by using it's bbox and the page where the chunk is in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d57d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_retrieved_part(page_no,bbox):\n",
    "    doc = fitz.open(\"./docling.pdf\")\n",
    "    \n",
    "    page_no = page_no-1\n",
    "    page = doc[page_no] \n",
    "    \n",
    "    # bbox docling\n",
    "    l, r = bbox.l, bbox.r\n",
    "    t, b = bbox.t, bbox.b\n",
    "\n",
    "    # boîte réelle de PyMuPDF\n",
    "    page_w = page.rect.width\n",
    "    page_h = page.rect.height\n",
    "\n",
    "    # CONVERSION \n",
    "    x1 = l\n",
    "    x2 = r\n",
    "    y1 = page_h - t   # inversion Y\n",
    "    y2 = page_h - b   # inversion Y\n",
    "\n",
    "    rect = fitz.Rect(x1, y1, x2, y2)\n",
    "    annot = page.add_highlight_annot(rect)\n",
    "\n",
    "    doc.save(\"out.pdf\")\n",
    "    doc.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75780614",
   "metadata": {},
   "source": [
    "# Get all the attributes of the items of a document \n",
    "\n",
    "I wanted to have a type that contains all the information that a pdf contains . Let's create a specific class that process a document and returns the main information that we want .\n",
    "But before let's define an util function that will returns the  item that we want and that have a specific id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cfa59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import PdfFormatOption , DocumentConverter\n",
    "from docling.datamodel.pipeline_options import PictureDescriptionVlmOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling_core.types.doc import BoundingBox , TextItem, PictureItem, TableItem\n",
    "from docling.datamodel.document import DoclingDocument\n",
    "from docling.datamodel.pipeline_options import smolvlm_picture_description\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdcac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_picture_description = True\n",
    "pipeline_options.picture_description_options = (\n",
    "    smolvlm_picture_description  # <-- the model choice\n",
    ")\n",
    "pipeline_options.picture_description_options.prompt = (\n",
    "    \"Describe the image in three sentences. Be consise and accurate.\"\n",
    ")\n",
    "pipeline_options.images_scale = 2.0\n",
    "pipeline_options.generate_picture_images = True\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options,\n",
    "        )\n",
    "    }\n",
    ")\n",
    "c = converter.convert(\n",
    "    \"../Docling/docs/docling.pdf\"\n",
    ").document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a848344",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.pictures[4].annotations[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element_by_type_and_id(doc: DoclingDocument,\n",
    "                               type:str ,\n",
    "                               id: int):\n",
    "    \"\"\"Get an element by its type and its id\n",
    "\n",
    "    Args:\n",
    "        doc (DoclingDocument): The docling document\n",
    "        type (str): the type\n",
    "        id (int): the id\n",
    "\n",
    "    Raises:\n",
    "        Exception: If index out of range\n",
    "        \n",
    "    \"\"\"\n",
    "    if type not in [\"texts\",\"pictures\",\"tables\"]:\n",
    "        raise Exception(\"The type provided is not a correct type\\n=====REMINDER=======\\nTHE TYPE MUST BELONGS TO ['texts','pictures','tables']\")\n",
    "    \n",
    "    try:\n",
    "        elem = getattr(doc,type)\n",
    "        return elem[id]\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR WHILE TRYING TO FIND THE ASKED ELEMENT :\\n=====ERROR======\\n{e}\")\n",
    "        return \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c511b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pydantic model for text Items\n",
    "class TextAttributes(BaseModel):\n",
    "    text: str\n",
    "    bbox: BoundingBox | None\n",
    "    label: str\n",
    "    n_page: int | None\n",
    "\n",
    "#Pydantic model for Table attributes\n",
    "class TableAttributes(BaseModel):\n",
    "    bbox: BoundingBox |None\n",
    "    n_page: int | None\n",
    "    caption : list[TextAttributes] | None\n",
    "\n",
    "#Pydantic model for Image pictures\n",
    "class ImageAttributes(BaseModel):\n",
    "    bbox: BoundingBox | None\n",
    "    n_page: int |None\n",
    "    caption : list[TextAttributes]  | None\n",
    "    children_attributes : list[TextAttributes | TableAttributes] | None\n",
    "    base64_url : str\n",
    "    description : str | None\n",
    "\n",
    "\n",
    "    \n",
    "# Let's create first a pydantic model which will represent the attributes of every docling document\n",
    "class DocAttributes(BaseModel):\n",
    "    filename: str\n",
    "    n_text: int\n",
    "    n_pictures: int\n",
    "    n_tables: int\n",
    "    texts: list[TextAttributes]\n",
    "    images: list[ImageAttributes]\n",
    "    tables: list[TableAttributes]\n",
    "    \n",
    "class DocumentProcessor:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 do_ocr : bool = True,\n",
    "                 do_table:bool = True,\n",
    "                 use_smolVlm: bool  = True,\n",
    "                 generate_pic: bool = True\n",
    "                 ):\n",
    "        \n",
    "        pipeline = PdfPipelineOptions(\n",
    "            do_ocr= do_ocr,\n",
    "            do_table_structure=do_table,\n",
    "            #We keep the base64 image if we want it later to show it to the use\n",
    "            generate_picture_images= generate_pic,\n",
    "            do_picture_description=True,\n",
    "        )\n",
    "        \n",
    "        if use_smolVlm:\n",
    "            pipeline.picture_description_options= smolvlm_picture_description\n",
    "            pipeline.picture_description_options.prompt = \"Describe the image in three sentences. Be consise and accurate.\"\n",
    "            \n",
    "        self.converter = DocumentConverter(\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline)\n",
    "            }\n",
    "        )\n",
    "\n",
    "    \n",
    "    def process(self,\n",
    "                paths: list[str]) -> list[DoclingDocument]:\n",
    "        \n",
    "        \n",
    "        #Verify if there is a doc path\n",
    "        if not paths or len(paths)==0:\n",
    "            raise Exception(\"No paths detected . Verify your arguments\")\n",
    "        \n",
    "        #Convert all avery documents to a docling document\n",
    "        docling_docs = []\n",
    "        for path in paths :\n",
    "            docling_docs.append(\n",
    "                self.converter.convert(path).document\n",
    "            )\n",
    "        return docling_docs\n",
    "            \n",
    "    def generate_attributes(self,\n",
    "                            docs : list[DoclingDocument]):\n",
    "        \n",
    "        \"\"\"Generate all the attributes for every document\n",
    "\n",
    "        Args:\n",
    "            docling_docs (list[DoclingDocument]): List of DocLing documents\n",
    "        \"\"\"\n",
    "        \n",
    "        #If there is not documents raise the Error\n",
    "        if len(docs) ==0 :\n",
    "            raise ValueError(\"No documents provided , try again \")\n",
    "        \n",
    "        \n",
    "        def _process_text(item:TextItem) -> TextAttributes:\n",
    "            text_att = TextAttributes(\n",
    "                text=item.text,\n",
    "                label=item.label.name.lower(),\n",
    "                n_page=item.prov[0].page_no if item.prov else None,\n",
    "                bbox=item.prov[0].bbox if item.prov else None\n",
    "            )\n",
    "            return text_att\n",
    "        \n",
    "        \n",
    "        def _process_image(item:PictureItem,\n",
    "                            doc:DoclingDocument):\n",
    "            \n",
    "            children_att_list = []\n",
    "            if item.children:\n",
    "                for children in item.children:\n",
    "                    type = children.cref.split(\"/\")[1]\n",
    "                    element = get_element_by_type_and_id(\n",
    "                        doc=doc,\n",
    "                        id=int(children.cref.split(\"/\")[2]),\n",
    "                        type=type\n",
    "                    )\n",
    "                    if type == \"texts\" and element is not None:\n",
    "                        children_att_list.append(_process_text(element))\n",
    "                    elif type == \"tables\" and element is not None:\n",
    "                        \n",
    "                        children_att_list.append(_process_table(element, doc))\n",
    "                        \n",
    "            #Store the captions of every picture if there is one\n",
    "            if item.captions:\n",
    "                captions_list = []\n",
    "                for c in item.captions:\n",
    "                    id = int(c.cref.split(\"/\")[2])\n",
    "                    elem = get_element_by_type_and_id(\n",
    "                        doc=doc,\n",
    "                        id=id,\n",
    "                        type=\"texts\"\n",
    "                    )\n",
    "                    captions_list.append(_process_text(item=elem))\n",
    "                    \n",
    "            image_att = ImageAttributes(\n",
    "                caption= captions_list if item.captions else None,\n",
    "                n_page=item.prov[0].page_no if item.prov else None,\n",
    "                bbox=item.prov[0].bbox if item.prov else None,\n",
    "                base64_url=item.image.uri.__str__() if item.image and item.image.uri else \"\",\n",
    "                children_attributes=children_att_list if children_att_list else None,\n",
    "                description= item.annotations[0].text if item.annotations else None\n",
    "            )\n",
    "\n",
    "            \n",
    "            return image_att\n",
    "        \n",
    "        def _process_table(item:TableItem,\n",
    "                           doc: DoclingDocument):\n",
    "            \n",
    "            if item.captions:\n",
    "                captions_list = []\n",
    "                for c in item.captions:\n",
    "                    id = int(c.cref.split(\"/\")[2])\n",
    "                    elem = get_element_by_type_and_id(\n",
    "                        doc=doc,\n",
    "                        id=id,\n",
    "                        type=\"texts\"\n",
    "                    )\n",
    "                    captions_list.append(_process_text(item=elem))\n",
    "                    \n",
    "            table = TableAttributes(\n",
    "                    caption=captions_list if item.captions else None,\n",
    "                    n_page=item.prov[0].page_no if item.prov else None,\n",
    "                    bbox=item.prov[0].bbox if item.prov else None\n",
    "                )\n",
    "\n",
    "            \n",
    "            return table\n",
    "    \n",
    "        #Let's begin our processing\n",
    "        \n",
    "        doc_attributes_list = []\n",
    "        \n",
    "        for doc in docs:\n",
    "            n_images = len(doc.pictures)\n",
    "            n_tables = len(doc.tables)\n",
    "            n_texts = len(doc.texts)\n",
    "            \n",
    "            if n_texts > 0:\n",
    "                texts_attributes_list =[]\n",
    "                for text in doc.texts:\n",
    "                    text_att = _process_text(text)\n",
    "                    texts_attributes_list.append(text_att)\n",
    "                    \n",
    "            if n_images > 0:\n",
    "                images_attributes_list =[] \n",
    "                for image in doc.pictures:\n",
    "                    image_att = _process_image(image,doc)\n",
    "                    images_attributes_list.append(image_att)\n",
    "        \n",
    "            if n_tables > 0:\n",
    "                tables_attributes_list =[] \n",
    "                for table in doc.tables:\n",
    "                    table_att = _process_table(table,doc)\n",
    "                    tables_attributes_list.append(table_att)\n",
    "            \n",
    "            doc_attribute = DocAttributes(\n",
    "                filename=doc.origin.filename,\n",
    "                n_pictures=n_images,\n",
    "                n_tables=n_tables,\n",
    "                n_text=n_texts,\n",
    "                images=images_attributes_list,\n",
    "                texts= texts_attributes_list,\n",
    "                tables=tables_attributes_list \n",
    "            )\n",
    "\n",
    "            doc_attributes_list.append(doc_attribute)\n",
    "        \n",
    "        return doc_attributes_list\n",
    "        \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd51d95c",
   "metadata": {},
   "source": [
    "Here we are let's try the code and see what we got !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465cf2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DocumentProcessor()\n",
    "paths = [\"../Docling/docs/docling.pdf\",\"../Docling/docs/trans.pdf\"]\n",
    "docling_docs = processor.process(paths=paths)\n",
    "doc_attributes = processor.generate_attributes(docling_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9618c2b",
   "metadata": {},
   "source": [
    "# Chunking part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fb0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.chunking import HybridChunker\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "TOKENIZER_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_MODEL_ID)\n",
    "\n",
    "#We intialize the chunker\n",
    "chunker = HybridChunker(\n",
    "    tokenizer=tokenizer,\n",
    "    \n",
    ")\n",
    "\n",
    "#The chunker outputs an iterable object \n",
    "chunk_iter = chunker.chunk(dl_doc=docling_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6adf10",
   "metadata": {},
   "source": [
    "Let's see what the chunks contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab675a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks =[]\n",
    "for i,chunk in enumerate(chunk_iter):\n",
    "    chunks.append(chunk)\n",
    "    print(f\"=== {i} ===\")\n",
    "    print(f\"chunk.text:\\n{f'{chunk.text}…'!r}\")\n",
    "\n",
    "    enriched_text = chunker.contextualize(chunk=chunk)\n",
    "    print(f\"chunker.contextualize(chunk):\\n{f'{enriched_text[:300]}…'!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1513204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Any\n",
    "from docling.chunking import HybridChunker\n",
    "from transformers import AutoTokenizer\n",
    "from typing_extensions import override\n",
    "from docling_core.transforms.chunker import BaseChunk\n",
    "from docling_core.types.doc.labels import DocItemLabel\n",
    "from docling_core.types.doc.document import DocItem, PictureItem ,PictureDescriptionData\n",
    "from docling_core.types.doc.document import BoundingBox\n",
    "from docling_core.transforms.chunker.hierarchical_chunker import DocChunk\n",
    "from docling_core.transforms.serializer.common import create_ser_result\n",
    "from docling_core.transforms.chunker.hierarchical_chunker import (\n",
    "    ChunkingDocSerializer,ChunkingSerializerProvider\n",
    ")\n",
    "from docling_core.transforms.serializer.markdown import MarkdownTableSerializer, MarkdownPictureSerializer\n",
    "\n",
    "#Here is my type of chunks where i gather a lot of information that will be useful after \n",
    "class CoolChunk(BaseModel):\n",
    "    contextualized_chunk: str\n",
    "    bboxes : list[BoundingBox]\n",
    "    n_pages : list[int]\n",
    "    origin: str\n",
    "    labels: list[str]\n",
    "\n",
    "\n",
    "\n",
    "#Here we define a custom picture serialization strategy which leverages picture annotations\n",
    "class AnnotationPictureSerializer(MarkdownPictureSerializer):\n",
    "    @override\n",
    "    def serialize(self, *, item, doc_serializer, doc, **kwargs):\n",
    "        \n",
    "        texts : list[str] = []\n",
    "        for annotation in item:\n",
    "            if isinstance(annotation,PictureDescriptionData):\n",
    "                texts.append(f\"Picture description: {annotation.text}\")\n",
    "    \n",
    "        text_res = \"\\n\".join(texts)\n",
    "        text_res = doc_serializer.post_process(text=text_res)\n",
    "        return create_ser_result(text=text_res, span_source=item)\n",
    "    \n",
    "#Here we define a serializer provider that contains the table and Picture special serialization strategies\n",
    "class MySerializerProvider(ChunkingSerializerProvider):\n",
    "    def get_serializer(self, doc):\n",
    "        return ChunkingDocSerializer(\n",
    "            doc=doc,\n",
    "            picture_serializer=AnnotationPictureSerializer(),\n",
    "            table_serializer=MarkdownTableSerializer()\n",
    "        )\n",
    "    \n",
    "class MyChunker:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 tokenizer_model:str = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "                 ):\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_model)\n",
    "        self.chunker = HybridChunker(tokenizer=self.tokenizer,\n",
    "                                     serializer_provider=MySerializerProvider())\n",
    "    \n",
    "        \n",
    "    def chunk(self,\n",
    "              doc: DoclingDocument,\n",
    "              verbose: bool = True) -> list[CoolChunk]:\n",
    "        \n",
    "        def _get_items(items:list) -> list[DocItem]:\n",
    "            l = []\n",
    "            for item in items:\n",
    "                l.append(item) \n",
    "            return l\n",
    "                \n",
    "        chunks = list(self.chunker.chunk(dl_doc=doc))\n",
    "        chunks_lists = []\n",
    "        \n",
    "        for i,chunk in enumerate(chunks):\n",
    "            l_items = _get_items(chunk.meta.doc_items)\n",
    "            if verbose:\n",
    "                print(f\"========= items of chunk n°{i} extracted ==============\\n \")\n",
    "            chunks_lists.append(\n",
    "            \n",
    "                CoolChunk(\n",
    "                    bboxes= [item.prov[0].bbox for item in l_items if item.prov],\n",
    "                    contextualized_chunk= self.chunker.contextualize(chunk),\n",
    "                    labels= [item.label[:] for item in l_items if item.label ],\n",
    "                    n_pages=[item.prov[0].page_no for item in l_items if item.prov ],\n",
    "                    origin= chunk.meta.origin.filename\n",
    "                )\n",
    "            )\n",
    "            if verbose:\n",
    "                print(f\"========= CoolChunk n°{i} created ==============\\n \")\n",
    "        return chunks_lists\n",
    "\n",
    "    def get_chunks_type(self,\n",
    "                       type:str,\n",
    "                       chunks: list[CoolChunk]):\n",
    "        \n",
    "        if type not in [\"text\", \"picture\",'table',\"code\"]:\n",
    "            raise Exception(\"The provided type does not exists please choose between: 'text , 'picture', 'table'\")\n",
    "\n",
    "        type_list = []\n",
    "        for c in chunks :\n",
    "            if c.labels:\n",
    "                for l in c.labels:\n",
    "                    if  l == type:\n",
    "                        type_list.append(c)\n",
    "        return type_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68521d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker  = MyChunker()\n",
    "chunks = chunker.chunk(docling_docs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc83c5e",
   "metadata": {},
   "source": [
    "Here is an example of a complete workflow where you only have to create a converter and chunks your documents . It uses SmolVLM for the VLM part and use the defined Serialiasation strategies above to create picture and table chunks in the chunking part ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Docling/docs/docling.pdf\"\n",
    "\n",
    "#Create the DocumentProcessor\n",
    "DocProcessor = DocumentProcessor(\n",
    "    do_ocr=False,\n",
    "    do_table=True,\n",
    "    generate_pic=False,\n",
    "    use_smolVlm=True\n",
    ")\n",
    "\n",
    "#Process\n",
    "docling_doc = DocProcessor.process(\n",
    "    paths = [path]\n",
    ")\n",
    "\n",
    "#Chunk the doc \n",
    "chunker = MyChunker()\n",
    "chunks = chunker.chunk(\n",
    "    doc=docling_doc[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf51cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_docling import  DoclingLoader\n",
    "\n",
    "loader = DoclingLoader(\n",
    "    file_path=\"../Docling/docs/docling.pdf\",\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc317639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Version 1.0\\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\\nAI4K Group, IBM Research R¨ uschlikon, Switzerland'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4f41662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m\n",
      "DoclingLoader(\n",
      "    file_path: Union[str, Iterable[str]],\n",
      "    *,\n",
      "    converter: Optional[docling.document_converter.DocumentConverter] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    convert_kwargs: Optional[Dict[str, Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    export_type: langchain_docling.loader.ExportType = <ExportType.DOC_CHUNKS: \u001b[33m'doc_chunks'\u001b[39m>,\n",
      "    md_export_kwargs: Optional[dict[str, Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    chunker: Optional[docling_core.transforms.chunker.base.BaseChunker] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    meta_extractor: Optional[langchain_docling.loader.BaseMetaExtractor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      ")\n",
      "\u001b[31mSource:\u001b[39m        \n",
      "\u001b[38;5;28;01mclass\u001b[39;00m DoclingLoader(BaseLoader):\n",
      "    \u001b[33m\"\"\"Docling Loader.\"\"\"\u001b[39m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __init__(\n",
      "        self,\n",
      "        file_path: Union[str, Iterable[str]],\n",
      "        *,\n",
      "        converter: Optional[DocumentConverter] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        convert_kwargs: Optional[Dict[str, Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        export_type: ExportType = ExportType.DOC_CHUNKS,\n",
      "        md_export_kwargs: Optional[dict[str, Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        chunker: Optional[BaseChunker] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        meta_extractor: Optional[BaseMetaExtractor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ):\n",
      "        \u001b[33m\"\"\"Initialize with a file path.\u001b[39m\n",
      "\n",
      "\u001b[33m        Args:\u001b[39m\n",
      "\u001b[33m            file_path: File source as single str (URL or local file) or Iterable\u001b[39m\n",
      "\u001b[33m                thereof.\u001b[39m\n",
      "\u001b[33m            converter: Any specific `DocumentConverter` to use. Defaults to `None` (i.e.\u001b[39m\n",
      "\u001b[33m                converter defined internally).\u001b[39m\n",
      "\u001b[33m            convert_kwargs: Any specific kwargs to pass to conversion invocation.\u001b[39m\n",
      "\u001b[33m                Defaults to `None` (i.e. behavior defined internally).\u001b[39m\n",
      "\u001b[33m            export_type: The type to export to: either `ExportType.MARKDOWN` (outputs\u001b[39m\n",
      "\u001b[33m                Markdown of whole input file) or `ExportType.DOC_CHUNKS` (outputs chunks\u001b[39m\n",
      "\u001b[33m                based on chunker).\u001b[39m\n",
      "\u001b[33m            md_export_kwargs: Any specific kwargs to pass to Markdown export (in case of\u001b[39m\n",
      "\u001b[33m                `ExportType.MARKDOWN`). Defaults to `None` (i.e. behavior defined\u001b[39m\n",
      "\u001b[33m                internally).\u001b[39m\n",
      "\u001b[33m            chunker: Any specific `BaseChunker` to use (in case of\u001b[39m\n",
      "\u001b[33m                `ExportType.DOC_CHUNKS`). Defaults to `None` (i.e. chunker defined\u001b[39m\n",
      "\u001b[33m                internally).\u001b[39m\n",
      "\u001b[33m            meta_extractor: The extractor instance to use for populating the output\u001b[39m\n",
      "\u001b[33m                document metadata; if not set, a system default is used.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        self._file_paths = (\n",
      "            file_path\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(file_path, Iterable) \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(file_path, str)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m [file_path]\n",
      "        )\n",
      "\n",
      "        self._converter: DocumentConverter = converter \u001b[38;5;28;01mor\u001b[39;00m DocumentConverter()\n",
      "        self._convert_kwargs = convert_kwargs \u001b[38;5;28;01mif\u001b[39;00m convert_kwargs \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "        self._export_type = export_type\n",
      "        self._md_export_kwargs = (\n",
      "            md_export_kwargs\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m md_export_kwargs \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m {\u001b[33m\"image_placeholder\"\u001b[39m: \u001b[33m\"\"\u001b[39m}\n",
      "        )\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self._export_type == ExportType.DOC_CHUNKS:\n",
      "            self._chunker: BaseChunker = chunker \u001b[38;5;28;01mor\u001b[39;00m HybridChunker()\n",
      "        self._meta_extractor = meta_extractor \u001b[38;5;28;01mor\u001b[39;00m MetaExtractor()\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m lazy_load(\n",
      "        self,\n",
      "    ) -> Iterator[Document]:\n",
      "        \u001b[33m\"\"\"Lazy load documents.\"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;28;01min\u001b[39;00m self._file_paths:\n",
      "            conv_res = self._converter.convert(\n",
      "                source=file_path,\n",
      "                **self._convert_kwargs,\n",
      "            )\n",
      "            dl_doc = conv_res.document\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m self._export_type == ExportType.MARKDOWN:\n",
      "                \u001b[38;5;28;01myield\u001b[39;00m Document(\n",
      "                    page_content=dl_doc.export_to_markdown(**self._md_export_kwargs),\n",
      "                    metadata=self._meta_extractor.extract_dl_doc_meta(\n",
      "                        file_path=file_path,\n",
      "                        dl_doc=dl_doc,\n",
      "                    ),\n",
      "                )\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m self._export_type == ExportType.DOC_CHUNKS:\n",
      "                chunk_iter = self._chunker.chunk(dl_doc)\n",
      "                \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;28;01min\u001b[39;00m chunk_iter:\n",
      "                    \u001b[38;5;28;01myield\u001b[39;00m Document(\n",
      "                        page_content=self._chunker.contextualize(chunk=chunk),\n",
      "                        metadata=self._meta_extractor.extract_chunk_meta(\n",
      "                            file_path=file_path,\n",
      "                            chunk=chunk,\n",
      "                        ),\n",
      "                    )\n",
      "\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(f\"Unexpected export type: {self._export_type}\")\n",
      "\u001b[31mFile:\u001b[39m           ~/Documents/Python/ML/.venv/lib/python3.12/site-packages/langchain_docling/loader.py\n",
      "\u001b[31mType:\u001b[39m           ABCMeta\n",
      "\u001b[31mSubclasses:\u001b[39m     "
     ]
    }
   ],
   "source": [
    "from langchain_core.document_loaders import BaseLoader\n",
    "\n",
    "\n",
    "BaseLoader??\n",
    "DoclingLoader??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
